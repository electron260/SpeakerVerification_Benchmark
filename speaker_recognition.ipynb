{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.resnet.resnet_se_34v2 import ResNetSE34V2\n",
    "from torchaudio.transforms import MelSpectrogram\n",
    "from torchaudio.functional import amplitude_to_DB\n",
    "import torch\n",
    "import torchaudio\n",
    "import librosa\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import yaml\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/hugo/Desktop/Projects/audio_analysis/SpeakerVerification_Benchmark\n"
     ]
    }
   ],
   "source": [
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH = \"IEMOCAP_full_release\"\n",
    "PATH = os.path.join(os.getcwd(), DATASET_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Session4\n",
      "Ses04M_script03_1\n",
      "Ses04M_script01_3\n",
      "Session3\n",
      "Ses03F_script02_2\n",
      "Ses03M_impro07\n",
      "Session2\n",
      "Ses02F_script01_1\n",
      "Ses02M_script03_2\n",
      "Session5\n",
      "Ses05F_impro08\n",
      "Ses05M_script01_1b\n",
      "Session1\n",
      "Ses01F_impro06\n",
      "Ses01M_script01_3\n"
     ]
    }
   ],
   "source": [
    "data = []\n",
    "\n",
    "for i, subdir in enumerate(os.listdir(PATH)):\n",
    "    #if subdir in [\"Benjamin_Netanyau\", \"Julia_Gillard\", \"Jens_Stoltenberg\", \"Margaret_Tarcher\", \"Nelson_Mandela\"]:\n",
    "\n",
    "    if (subdir[0] != '.'):\n",
    "        #for j in random.sample(range(0, 20), 2):\n",
    "        #for i, file in enumerate(os.listdir(os.path.join(PATH, subdir)+'/sentences/wav')):\n",
    "        print(subdir)\n",
    "        #Choose 2 random file in a directory \n",
    "        for j in random.sample(range(0, 20), 2):\n",
    "            file = os.listdir(os.path.join(PATH, subdir)+'/sentences/wav')[j]\n",
    "            print(file)\n",
    "            for k in random.sample(range(0, 20), 3):\n",
    "                file2 = os.listdir(PATH+'/'+subdir+'/sentences/wav/'+file)[k]\n",
    "                \n",
    "\n",
    "                if file2[-8] == 'M' :\n",
    "                    data.append([PATH+'/'+subdir+'/sentences/wav/'+file+\"/\"+file2, \"Spk_\"+str(2*int(subdir[-1])-1)])\n",
    "                else :\n",
    "                    data.append([PATH+'/'+subdir+'/sentences/wav/'+file+\"/\"+file2, \"Spk_\"+str(2*int(subdir[-1]))])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_audio(file):\n",
    "    EPS = 1e-8\n",
    "    s, _ = librosa.load(file, sr=16000)\n",
    "    amax = np.max(np.abs(s))\n",
    "    factor = 1.0 / (amax + EPS)\n",
    "    s = s * factor\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['/Users/hugo/Desktop/Projects/audio_analysis/SpeakerVerification_Benchmark/IEMOCAP_full_release/Session4/sentences/wav/Ses04F_script01_3/Ses04F_script01_3_M013.wav', 'Spk_7'], ['/Users/hugo/Desktop/Projects/audio_analysis/SpeakerVerification_Benchmark/IEMOCAP_full_release/Session4/sentences/wav/Ses04F_script01_3/Ses04F_script01_3_F027.wav', 'Spk_8'], ['/Users/hugo/Desktop/Projects/audio_analysis/SpeakerVerification_Benchmark/IEMOCAP_full_release/Session4/sentences/wav/Ses04F_script01_3/Ses04F_script01_3_M006.wav', 'Spk_7'], ['/Users/hugo/Desktop/Projects/audio_analysis/SpeakerVerification_Benchmark/IEMOCAP_full_release/Session4/sentences/wav/Ses04F_script02_1/Ses04F_script02_1_M039.wav', 'Spk_7'], ['/Users/hugo/Desktop/Projects/audio_analysis/SpeakerVerification_Benchmark/IEMOCAP_full_release/Session4/sentences/wav/Ses04F_script02_1/Ses04F_script02_1_M012.wav', 'Spk_7'], ['/Users/hugo/Desktop/Projects/audio_analysis/SpeakerVerification_Benchmark/IEMOCAP_full_release/Session4/sentences/wav/Ses04F_script02_1/Ses04F_script02_1_M011.wav', 'Spk_7'], ['/Users/hugo/Desktop/Projects/audio_analysis/SpeakerVerification_Benchmark/IEMOCAP_full_release/Session3/sentences/wav/Ses03M_script03_2/Ses03M_script03_2_M009.wav', 'Spk_5'], ['/Users/hugo/Desktop/Projects/audio_analysis/SpeakerVerification_Benchmark/IEMOCAP_full_release/Session3/sentences/wav/Ses03M_script03_2/Ses03M_script03_2_M034.wav', 'Spk_5'], ['/Users/hugo/Desktop/Projects/audio_analysis/SpeakerVerification_Benchmark/IEMOCAP_full_release/Session3/sentences/wav/Ses03M_script03_2/Ses03M_script03_2_M041.wav', 'Spk_5'], ['/Users/hugo/Desktop/Projects/audio_analysis/SpeakerVerification_Benchmark/IEMOCAP_full_release/Session3/sentences/wav/Ses03M_impro05b/Ses03M_impro05b_F003.wav', 'Spk_6'], ['/Users/hugo/Desktop/Projects/audio_analysis/SpeakerVerification_Benchmark/IEMOCAP_full_release/Session3/sentences/wav/Ses03M_impro05b/Ses03M_impro05b_M018.wav', 'Spk_5'], ['/Users/hugo/Desktop/Projects/audio_analysis/SpeakerVerification_Benchmark/IEMOCAP_full_release/Session3/sentences/wav/Ses03M_impro05b/Ses03M_impro05b_M019.wav', 'Spk_5'], ['/Users/hugo/Desktop/Projects/audio_analysis/SpeakerVerification_Benchmark/IEMOCAP_full_release/Session2/sentences/wav/Ses02F_script01_1/Ses02F_script01_1_F043.wav', 'Spk_4'], ['/Users/hugo/Desktop/Projects/audio_analysis/SpeakerVerification_Benchmark/IEMOCAP_full_release/Session2/sentences/wav/Ses02F_script01_1/Ses02F_script01_1_M039.wav', 'Spk_3'], ['/Users/hugo/Desktop/Projects/audio_analysis/SpeakerVerification_Benchmark/IEMOCAP_full_release/Session2/sentences/wav/Ses02F_script01_1/Ses02F_script01_1_F041.wav', 'Spk_4'], ['/Users/hugo/Desktop/Projects/audio_analysis/SpeakerVerification_Benchmark/IEMOCAP_full_release/Session2/sentences/wav/Ses02M_impro02/Ses02M_impro02_M000.wav', 'Spk_3'], ['/Users/hugo/Desktop/Projects/audio_analysis/SpeakerVerification_Benchmark/IEMOCAP_full_release/Session2/sentences/wav/Ses02M_impro02/Ses02M_impro02_F012.wav', 'Spk_4'], ['/Users/hugo/Desktop/Projects/audio_analysis/SpeakerVerification_Benchmark/IEMOCAP_full_release/Session2/sentences/wav/Ses02M_impro02/Ses02M_impro02_F003.wav', 'Spk_4'], ['/Users/hugo/Desktop/Projects/audio_analysis/SpeakerVerification_Benchmark/IEMOCAP_full_release/Session5/sentences/wav/Ses05M_impro02/Ses05M_impro02_M023.wav', 'Spk_9'], ['/Users/hugo/Desktop/Projects/audio_analysis/SpeakerVerification_Benchmark/IEMOCAP_full_release/Session5/sentences/wav/Ses05M_impro02/Ses05M_impro02_F000.wav', 'Spk_10'], ['/Users/hugo/Desktop/Projects/audio_analysis/SpeakerVerification_Benchmark/IEMOCAP_full_release/Session5/sentences/wav/Ses05M_impro02/Ses05M_impro02_M009.wav', 'Spk_9'], ['/Users/hugo/Desktop/Projects/audio_analysis/SpeakerVerification_Benchmark/IEMOCAP_full_release/Session5/sentences/wav/Ses05F_script01_3/Ses05F_script01_3_M004.wav', 'Spk_9'], ['/Users/hugo/Desktop/Projects/audio_analysis/SpeakerVerification_Benchmark/IEMOCAP_full_release/Session5/sentences/wav/Ses05F_script01_3/Ses05F_script01_3_M005.wav', 'Spk_9'], ['/Users/hugo/Desktop/Projects/audio_analysis/SpeakerVerification_Benchmark/IEMOCAP_full_release/Session5/sentences/wav/Ses05F_script01_3/Ses05F_script01_3_F024.wav', 'Spk_10'], ['/Users/hugo/Desktop/Projects/audio_analysis/SpeakerVerification_Benchmark/IEMOCAP_full_release/Session1/sentences/wav/Ses01M_impro03/Ses01M_impro03_F013.wav', 'Spk_2'], ['/Users/hugo/Desktop/Projects/audio_analysis/SpeakerVerification_Benchmark/IEMOCAP_full_release/Session1/sentences/wav/Ses01M_impro03/Ses01M_impro03_F005.wav', 'Spk_2'], ['/Users/hugo/Desktop/Projects/audio_analysis/SpeakerVerification_Benchmark/IEMOCAP_full_release/Session1/sentences/wav/Ses01M_impro03/Ses01M_impro03_F011.wav', 'Spk_2'], ['/Users/hugo/Desktop/Projects/audio_analysis/SpeakerVerification_Benchmark/IEMOCAP_full_release/Session1/sentences/wav/Ses01F_script03_1/Ses01F_script03_1_F002.wav', 'Spk_2'], ['/Users/hugo/Desktop/Projects/audio_analysis/SpeakerVerification_Benchmark/IEMOCAP_full_release/Session1/sentences/wav/Ses01F_script03_1/Ses01F_script03_1_M037.wav', 'Spk_1'], ['/Users/hugo/Desktop/Projects/audio_analysis/SpeakerVerification_Benchmark/IEMOCAP_full_release/Session1/sentences/wav/Ses01F_script03_1/Ses01F_script03_1_F003.wav', 'Spk_2']]\n"
     ]
    }
   ],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding size is 256, encoder SAP.\n"
     ]
    }
   ],
   "source": [
    "with open('./models/resnet/config.yaml') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "sd = torch.load('./models/weigths/resnetse34_epoch92_eer0.00931.pth')\n",
    "model = ResNetSE34V2(nOut=256, n_mels= 80)\n",
    "model.load_state_dict(sd)\n",
    "model.eval()\n",
    "torch.set_grad_enabled(False)\n",
    "\n",
    "transform = MelSpectrogram(\n",
    "    sample_rate= 16000,\n",
    "    n_fft= 512,\n",
    "    win_length= 400,\n",
    "    hop_length= 160,\n",
    "    window_fn=torch.hamming_window,\n",
    "    n_mels= 80,\n",
    "    f_min=20,\n",
    "    f_max=7600,\n",
    "    norm='slaney')\n",
    "\n",
    "\n",
    "def embed_inference(audio_path, transform= transform, model = model):\n",
    "    s = load_audio(audio_path)\n",
    "    #print(type(s))\n",
    "    x = torch.from_numpy(s[None, :])\n",
    "    x = transform(x)\n",
    "    x = amplitude_to_DB(\n",
    "        x, multiplier=10, amin= 1e-5, db_multiplier=0, top_db=75)\n",
    "\n",
    "    feature = model(x[:, None, :, :])\n",
    "    feature = torch.nn.functional.normalize(feature)\n",
    "    return(feature,s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = torch.nn.CosineSimilarity(dim=1, eps=1e-8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PROCESS THE TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchaudio\n",
    "from speechbrain.pretrained import EncoderClassifier\n",
    "classifier = EncoderClassifier.from_hparams(source=\"speechbrain/spkrec-ecapa-voxceleb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-10 11:40:04,455 - modelscope - INFO - PyTorch version 2.1.0 Found.\n",
      "2023-10-10 11:40:04,457 - modelscope - INFO - Loading ast index from /Users/hugo/.cache/modelscope/ast_indexer\n",
      "2023-10-10 11:40:04,499 - modelscope - INFO - No valid ast index found from /Users/hugo/.cache/modelscope/ast_indexer, generating ast index from prebuilt!\n",
      "2023-10-10 11:40:04,551 - modelscope - INFO - Loading done! Current index file version is 1.9.2, with md5 95894f5bac47d08b4fba17db5dc4d12a and a total number of 941 components indexed\n",
      "2023-10-10 11:40:18,133 - modelscope - INFO - Model revision not specified, use revision: v1.0.2\n",
      "2023-10-10 11:40:19,113 - modelscope - INFO - initiate model from /Users/hugo/.cache/modelscope/hub/damo/speech_campplus_sv_en_voxceleb_16k\n",
      "2023-10-10 11:40:19,116 - modelscope - INFO - initiate model from location /Users/hugo/.cache/modelscope/hub/damo/speech_campplus_sv_en_voxceleb_16k.\n",
      "2023-10-10 11:40:19,120 - modelscope - INFO - initialize model from /Users/hugo/.cache/modelscope/hub/damo/speech_campplus_sv_en_voxceleb_16k\n",
      "2023-10-10 11:40:19,130 - modelscope - INFO - cuda is not available, using cpu instead.\n",
      "2023-10-10 11:40:19,424 - modelscope - WARNING - No preprocessor field found in cfg.\n",
      "2023-10-10 11:40:19,425 - modelscope - WARNING - No val key and type key found in preprocessor domain of configuration.json file.\n",
      "2023-10-10 11:40:19,425 - modelscope - WARNING - Cannot find available config to build preprocessor at mode inference, current config: {'model_dir': '/Users/hugo/.cache/modelscope/hub/damo/speech_campplus_sv_en_voxceleb_16k'}. trying to build by task and model information.\n",
      "2023-10-10 11:40:19,425 - modelscope - WARNING - No preprocessor key ('cam++-sv', 'speaker-verification') found in PREPROCESSOR_MAP, skip building preprocessor.\n",
      "2023-10-10 11:40:19,427 - modelscope - INFO - cuda is not available, using cpu instead.\n"
     ]
    }
   ],
   "source": [
    "from modelscope.pipelines import pipeline\n",
    "\n",
    "sv_pipeline = pipeline(\n",
    "    task='speaker-verification',\n",
    "    model='damo/speech_campplus_sv_en_voxceleb_16k'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from speechbrain.pretrained import SpeakerRecognition\n",
    "verification = SpeakerRecognition.from_hparams(source=\"speechbrain/spkrec-ecapa-voxceleb\", savedir=\"pretrained_models/spkrec-ecapa-voxceleb\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/30 [00:00<?, ?it/s][W NNPACK.cpp:64] Could not initialize NNPACK! Reason: Unsupported hardware.\n",
      "100%|██████████| 30/30 [23:02<00:00, 46.08s/it]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "compar_tab = pd.DataFrame(columns = ['spk_1', 'spk_2', 'duration_1', 'duration_2', 'score_classic', 'score_CAM++', 'TDN_score','path_1', 'path_2'])\n",
    "with tqdm(total=len(data)) as pbar:\n",
    "    for sample_1 in data :\n",
    "        spk_1 = sample_1[1]\n",
    "        ref_embed, audio_1 = embed_inference(sample_1[0])\n",
    "        for sample_2 in data :\n",
    "            spk_2 = sample_2[1]\n",
    "\n",
    "            \n",
    "            embed, audio_2 = embed_inference(sample_2[0])\n",
    "            loss_val = loss(ref_embed, embed)\n",
    "\n",
    "\n",
    "\n",
    "            cam_score = sv_pipeline([audio_1, audio_2])\n",
    "\n",
    "            TDN_score = verification.verify_files(sample_1[0], sample_2[0]) # Different Speakers\n",
    "            compar_tab.loc[len(compar_tab)] = [spk_1, spk_2, len(audio_1)/16000, len(audio_2)/16000, loss_val.item(), cam_score, TDN_score, sample_1[0], sample_2[0]]\n",
    "            #print(label, val)\n",
    "        pbar.update(1)\n",
    "       \n",
    "\n",
    "           \n",
    "compar_tab.to_csv('compar_tab.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_embed, audio = embed_inference(data[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.4199375\n"
     ]
    }
   ],
   "source": [
    "print(len(audio)/16000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************** CHOSEN TRESHOLD :  0.2  **********************\n",
      "For RESNET : False positive : 14 False negative : 144\n",
      "For CAM++ : False positive : 8 False negative : 80\n",
      "For TDN : False positive : 16 False negative : 40\n",
      "For RESNET : Accuracy : 0.8833333333333333\n",
      "For CAM++ : Accuracy : 0.9333333333333333\n",
      "For TDN : Accuracy : 0.8666666666666667\n",
      "********************** CHOSEN TRESHOLD :  0.3  **********************\n",
      "For RESNET : False positive : 40 False negative : 46\n",
      "For CAM++ : False positive : 24 False negative : 12\n",
      "For TDN : False positive : 34 False negative : 4\n",
      "For RESNET : Accuracy : 0.6666666666666666\n",
      "For CAM++ : Accuracy : 0.8\n",
      "For TDN : Accuracy : 0.7166666666666667\n",
      "********************** CHOSEN TRESHOLD :  0.4  **********************\n",
      "For RESNET : False positive : 60 False negative : 6\n",
      "For CAM++ : False positive : 52 False negative : 0\n",
      "For TDN : False positive : 66 False negative : 0\n",
      "For RESNET : Accuracy : 0.5\n",
      "For CAM++ : Accuracy : 0.5666666666666667\n",
      "For TDN : Accuracy : 0.45\n",
      "********************** CHOSEN TRESHOLD :  0.5  **********************\n",
      "For RESNET : False positive : 74 False negative : 0\n",
      "For CAM++ : False positive : 68 False negative : 0\n",
      "For TDN : False positive : 74 False negative : 0\n",
      "For RESNET : Accuracy : 0.38333333333333336\n",
      "For CAM++ : Accuracy : 0.43333333333333335\n",
      "For TDN : Accuracy : 0.38333333333333336\n",
      "********************** CHOSEN TRESHOLD :  0.6  **********************\n",
      "For RESNET : False positive : 80 False negative : 0\n",
      "For CAM++ : False positive : 80 False negative : 0\n",
      "For TDN : False positive : 82 False negative : 0\n",
      "For RESNET : Accuracy : 0.3333333333333333\n",
      "For CAM++ : Accuracy : 0.3333333333333333\n",
      "For TDN : Accuracy : 0.31666666666666665\n",
      "********************** CHOSEN TRESHOLD :  0.7  **********************\n",
      "For RESNET : False positive : 90 False negative : 0\n",
      "For CAM++ : False positive : 86 False negative : 0\n",
      "For TDN : False positive : 90 False negative : 0\n",
      "For RESNET : Accuracy : 0.25\n",
      "For CAM++ : Accuracy : 0.2833333333333333\n",
      "For TDN : Accuracy : 0.25\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('compar_tab.csv')\n",
    "\n",
    "false_positive_classic = 0\n",
    "false_positive_CAM = 0\n",
    "false_negative_classic = 0\n",
    "false_negative_CAM = 0\n",
    "false_positive_TDN = 0\n",
    "false_negative_TDN = 0\n",
    "positive = 0\n",
    "negative = 0\n",
    "treshold = 0.3\n",
    "\n",
    "for treshold in [0.2,0.3,0.4,0.5,0.6,0.7] :\n",
    "    print('********************** CHOSEN TRESHOLD : ', treshold, ' **********************')\n",
    "    for row, line in df.iterrows():\n",
    "        score_classic = line['score_classic']\n",
    "    \n",
    "        CAM = str_to_dict_cam(line['score_CAM++'])\n",
    "        score_CAM = float(CAM['score'])\n",
    "        \n",
    "        TDN = str_to_dict_TDN(line['TDN_score'])\n",
    "        score_TDN = float(TDN[0])\n",
    "\n",
    "        if line['spk_1'] == line['spk_2'] :\n",
    "            positive += 1\n",
    "            if score_classic < treshold :\n",
    "                false_positive_classic += 1\n",
    "            if score_CAM < treshold :\n",
    "                false_positive_CAM += 1\n",
    "            if score_TDN < treshold :\n",
    "                false_positive_TDN += 1\n",
    "        else :\n",
    "            negative += 1\n",
    "            if score_classic > treshold :\n",
    "                false_negative_classic += 1\n",
    "            if score_CAM > treshold :\n",
    "                false_negative_CAM += 1\n",
    "            if score_TDN > treshold :\n",
    "                false_negative_TDN += 1\n",
    "\n",
    "        \n",
    "    print(f'For RESNET : False positive : {false_positive_classic} False negative : {false_negative_classic}')\n",
    "    print(f'For CAM++ : False positive : {false_positive_CAM} False negative : {false_negative_CAM}')\n",
    "    print(f'For TDN : False positive : {false_positive_TDN} False negative : {false_negative_TDN}')\n",
    "    print(f'For RESNET : Accuracy : {(positive-false_positive_classic)/positive}')\n",
    "    print(f'For CAM++ : Accuracy : {(positive-false_positive_CAM)/positive}')   \n",
    "    print(f'For TDN : Accuracy : {(positive-false_positive_TDN)/positive}')\n",
    "\n",
    "    false_positive_classic = 0\n",
    "    false_positive_CAM = 0\n",
    "    false_negative_classic = 0\n",
    "    false_negative_CAM = 0\n",
    "    false_positive_TDN = 0\n",
    "    false_negative_TDN = 0\n",
    "    positive = 0\n",
    "    negative = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = '(tensor([1.0000]), tensor([True]))'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = \"{'score':1.0 , 'text':'hello'}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How to change a str written like {'score':1.0 , 'text':'hello'} to a dict\n",
    "def str_to_dict_cam(input : str):\n",
    "    input = input.replace(' ', '')\n",
    "    input = input.replace('{', '')\n",
    "    input = input.replace('}', '')\n",
    "    input = input.replace(\"'\", '')\n",
    "    input = input.split(',')\n",
    "    output = {}\n",
    "    for i in input :\n",
    "        i = i.split(':')\n",
    "        output[i[0]] = i[1]\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def str_to_dict_TDN(input : str):\n",
    "    input = input.replace('tensor', '')\n",
    "    input = input.replace(' ', '')\n",
    "    input = input.replace('{', '')\n",
    "    input = input.replace('}', '')\n",
    "    input = input.replace(\"'\", '')\n",
    "    input = input.replace(\"(\", '')\n",
    "    input = input.replace(\")\", '')\n",
    "    input = input.replace('[', '')\n",
    "    input = input.replace(']', '')\n",
    "\n",
    "    output = input.split(',')\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0000,True\n",
      "['1.0000', 'True']\n"
     ]
    }
   ],
   "source": [
    "print(str_to_dict_TDN(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
